{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and init all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "\n",
    "batch_size = 128\n",
    "image_len = 25\n",
    "flat_image_len = image_len * image_len\n",
    "\n",
    "# X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = input_data.read_data_sets(\"./data\", one_hot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all the functions that will help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(x, y):\n",
    "    '''\n",
    "    Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    unique = np.unique(y)\n",
    "    digit_indices = [np.where(y == i)[0] for i in unique]\n",
    "    # Looks like [array([7223]) 2.0]\n",
    "    negatives = np.array(filter(lambda x: len(x) == 1, digit_indices))\n",
    "    # Looks like [array([   33,  6178,  8623,  9490, 10098]) 1.0]\n",
    "    positives = np.array(filter(lambda x: len(x) >= 2, digit_indices))\n",
    "    for d in positives:\n",
    "        for i in range(len(d) / 2):\n",
    "            z1, z2 = d[i], d[i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "\n",
    "            z1, z2 = random.choice(negatives)[0], random.choice(negatives)[0]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def mlp(input_, input_dim, output_dim, name=\"mlp\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [input_dim, output_dim], tf.float32,\n",
    "                            tf.random_normal_initializer(mean=0.001, stddev=0.02))\n",
    "        return tf.nn.relu(tf.matmul(input_, w))\n",
    "\n",
    "\n",
    "def mlpnet(image, _dropout):\n",
    "    l1 = mlp(image, flat_image_len, batch_size, name='l1')\n",
    "    l1 = tf.nn.dropout(l1, _dropout)\n",
    "    l2 = mlp(l1, batch_size, batch_size, name='l2')\n",
    "    l2 = tf.nn.dropout(l2, _dropout)\n",
    "\n",
    "    l3 = mlp(l2, batch_size, batch_size, name='l3')\n",
    "    l3 = tf.nn.dropout(l3, _dropout)\n",
    "    l4 = mlp(l3, batch_size, batch_size, name='l4')\n",
    "    l4 = tf.nn.dropout(l4, _dropout)\n",
    "\n",
    "    l5 = mlp(l4, batch_size, batch_size, name='l5')\n",
    "    return l5\n",
    "\n",
    "\n",
    "def contrastive_loss(y, d):\n",
    "    tmp = y * tf.square(d)\n",
    "    tmp2 = (1 - y) * tf.square(tf.maximum((1 - d), 0))\n",
    "    return tf.reduce_sum(tmp + tmp2) / batch_size / 2\n",
    "\n",
    "\n",
    "def compute_accuracy(prediction, labels):\n",
    "    return labels[prediction.ravel() < 0.5].mean()\n",
    "\n",
    "\n",
    "def next_batch(s, e, inputs, labels):\n",
    "    sample = np.random.randint(len(inputs), size=batch_size)\n",
    "    input1 = inputs[sample, 0]\n",
    "    input2 = inputs[sample, 1]\n",
    "    y = np.reshape(labels[sample], (batch_size, 1))\n",
    "    return input1, input2, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create positive / negative pairs, models and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "print('Initializing the variables')\n",
    "init = tf.initialize_all_variables()\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.001\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 10, 0.1, staircase=True)\n",
    "\n",
    "# create training+test positive and negative pairs\n",
    "tr_pairs, tr_y = create_pairs(X_train, y_train)\n",
    "te_pairs, te_y = create_pairs(X_test, y_test)\n",
    "\n",
    "images_L = tf.placeholder(tf.float32, shape=([None, flat_image_len]), name='L')\n",
    "images_R = tf.placeholder(tf.float32, shape=([None, flat_image_len]), name='R')\n",
    "labels = tf.placeholder(tf.float32, shape=([None, 1]), name='gt')\n",
    "dropout_f = tf.placeholder(\"float\")\n",
    "\n",
    "print('Initializing the models')\n",
    "with tf.variable_scope(\"siamese\") as scope:\n",
    "    model1 = mlpnet(images_L, dropout_f)\n",
    "    scope.reuse_variables()\n",
    "    model2 = mlpnet(images_R, dropout_f)\n",
    "\n",
    "distance = tf.sqrt(tf.reduce_sum(tf.pow(tf.sub(model1, model2), 2), 1, keep_dims=True))\n",
    "loss = contrastive_loss(labels, distance)\n",
    "\n",
    "# contrastice loss\n",
    "t_vars = tf.trainable_variables()\n",
    "d_vars = [var for var in t_vars if 'l' in var.name]\n",
    "batch = tf.Variable(0)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the variables\n",
      "Initializing the models\n",
      "Launch the graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ugrad/h/haustind/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/users/ugrad/h/haustind/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  time: 0.896392 loss 0.13688 acc nan\n",
      "epoch 1  time: 0.876787 loss 0.12532 acc 54.60\n",
      "epoch 2  time: 0.900473 loss 0.12079 acc 56.42\n",
      "epoch 3  time: 1.114103 loss 0.11712 acc 59.16\n",
      "epoch 4  time: 0.885876 loss 0.11100 acc 62.35\n",
      "epoch 5  time: 0.893907 loss 0.10388 acc 65.41\n",
      "epoch 6  time: 0.879561 loss 0.10083 acc 66.60\n",
      "epoch 7  time: 0.891259 loss 0.09852 acc 67.64\n",
      "epoch 8  time: 1.009935 loss 0.09391 acc 69.88\n",
      "epoch 9  time: 0.921697 loss 0.09142 acc 70.46\n",
      "epoch 10  time: 0.879820 loss 0.09092 acc 70.98\n",
      "epoch 11  time: 0.973777 loss 0.08872 acc 71.49\n",
      "epoch 12  time: 0.882592 loss 0.08444 acc 74.06\n",
      "epoch 13  time: 0.898443 loss 0.07820 acc 76.06\n",
      "epoch 14  time: 0.985998 loss 0.07739 acc 76.79\n",
      "epoch 15  time: 0.969723 loss 0.07316 acc 77.57\n",
      "epoch 16  time: 0.979054 loss 0.07236 acc 78.41\n",
      "epoch 17  time: 0.932434 loss 0.06820 acc 80.17\n",
      "epoch 18  time: 0.977523 loss 0.06523 acc 81.42\n",
      "epoch 19  time: 0.936731 loss 0.06394 acc 81.74\n",
      "epoch 20  time: 0.975970 loss 0.06284 acc 82.29\n",
      "epoch 21  time: 0.980280 loss 0.05927 acc 83.84\n",
      "epoch 22  time: 1.003339 loss 0.05523 acc 84.83\n",
      "epoch 23  time: 0.904741 loss 0.05342 acc 85.30\n",
      "epoch 24  time: 0.947001 loss 0.05067 acc 86.53\n",
      "epoch 25  time: 1.074694 loss 0.04877 acc 87.22\n",
      "epoch 26  time: 0.901808 loss 0.04671 acc 88.24\n",
      "epoch 27  time: 0.886820 loss 0.04687 acc 87.82\n",
      "epoch 28  time: 0.906872 loss 0.04408 acc 88.20\n",
      "epoch 29  time: 0.871985 loss 0.04132 acc 89.19\n",
      "Accuract training set 92.03\n",
      "Accuract test set 64.11\n"
     ]
    }
   ],
   "source": [
    "print('Launch the graph')\n",
    "with tf.Session() as sess:\n",
    "    summary_writer = tf.train.SummaryWriter('./logs', sess.graph)\n",
    "\n",
    "    # sess.run(init)\n",
    "    tf.initialize_all_variables().run()\n",
    "    # Training cycle\n",
    "    for epoch in range(30):\n",
    "        avg_loss = 0.\n",
    "        avg_acc = 0.\n",
    "        total_batch = int(X_train.shape[0] / batch_size)\n",
    "        start_time = time.time()\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            s = i * batch_size\n",
    "            e = (i + 1) * batch_size\n",
    "            # Fit training using batch data\n",
    "            input1, input2, y = next_batch(s, e, tr_pairs, tr_y)\n",
    "            _, loss_value, predict = sess.run([optimizer, loss, distance],\n",
    "                                              feed_dict={images_L: input1, images_R: input2, labels: y, dropout_f: 0.9})\n",
    "            feature1 = model1.eval(feed_dict={images_L: input1, dropout_f: 0.9})\n",
    "            feature2 = model2.eval(feed_dict={images_R: input2, dropout_f: 0.9})\n",
    "            tr_acc = compute_accuracy(predict, y)\n",
    "            if math.isnan(tr_acc) and epoch != 0:\n",
    "                pass\n",
    "            avg_loss += loss_value\n",
    "            avg_acc += tr_acc * 100\n",
    "        duration = time.time() - start_time\n",
    "        print('epoch %d  time: %f loss %0.5f acc %0.2f' % (\n",
    "                epoch, duration, avg_loss / (total_batch), avg_acc / total_batch))\n",
    "    y = np.reshape(tr_y, (tr_y.shape[0], 1))\n",
    "    predict = distance.eval(feed_dict={images_L: tr_pairs[:, 0], images_R: tr_pairs[:, 1], labels: y, dropout_f: 1.0})\n",
    "    tr_acc = compute_accuracy(predict, y)\n",
    "    print('Accuract training set %0.2f' % (100 * tr_acc))\n",
    "\n",
    "    # Test model\n",
    "    predict = distance.eval(feed_dict={images_L: te_pairs[:, 0], images_R: te_pairs[:, 1], labels: y, dropout_f: 1.0})\n",
    "    y = np.reshape(te_y, (te_y.shape[0], 1))\n",
    "    te_acc = compute_accuracy(predict, y)\n",
    "    print('Accuract test set %0.2f' % (100 * te_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tensorboard screenshot showing that the architecture is, indeed, a siamese architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://s13.postimg.org/i75d2auh3/graph_run.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from StringIO import StringIO\n",
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://s13.postimg.org/i75d2auh3/graph_run.png\"\n",
    "Image(url= url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of train/test split**\n",
    "\n",
    "I did a 80/20 train/test split using `train_test_split(X, y, test_size=0.2)`. To get the +/- test split I divided the images into 2 groups where one contained only people who had a single image (SIG), the other containing images with multiple images per person(MIG). For each person in MIG I would add an equal number of pics from SIG to create a balanced +/- training set. \n",
    "\n",
    "\n",
    "**Description of resnet architecture** \n",
    "\n",
    "I used a 5 layer network with relus for my nonlinearities, and some dropout between each layer.\n",
    "\n",
    "\n",
    "**Assessed whether or not architecture was working**\n",
    "\n",
    "I used a distance scoring function along with a check of how many images where correctly classified.\n",
    "\n",
    "\n",
    "**The final performance of classifier**\n",
    "\n",
    "> epoch 29  time: 0.871985 loss 0.04132 acc 89.19\n",
    "\n",
    ">Accuract training set 92.03\n",
    "\n",
    ">Accuract test set 64.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
