{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import rnn_cell, seq2seq\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "\n",
    "from textloader import TextLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading preprocessed files\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# -------------------------------------------\n",
    "#\n",
    "# Global variables\n",
    "\n",
    "batch_size = 50\n",
    "sequence_length = 50\n",
    "data_loader = TextLoader(\".\", batch_size, sequence_length)\n",
    "grad_clip = 5\n",
    "vocab_size = data_loader.vocab_size  # dimension of one-hot encodings\n",
    "state_dim = 128\n",
    "\n",
    "num_layers = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "#\n",
    "\n",
    "# define placeholders for our inputs.\n",
    "# in_ph is assumed to be [batch_size,sequence_length]\n",
    "# targ_ph is assumed to be [batch_size,sequence_length]\n",
    "\n",
    "in_ph = tf.placeholder(tf.int32, [batch_size, sequence_length], name='inputs')\n",
    "targ_ph = tf.placeholder(tf.int32, [batch_size, sequence_length], name='targets')\n",
    "in_onehot = tf.one_hot(in_ph, vocab_size, name=\"input_onehot\")\n",
    "\n",
    "inputs = tf.split(1, sequence_length, in_onehot)\n",
    "inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "targets = tf.split(1, sequence_length, targ_ph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# at this point, inputs is a list of length sequence_length\n",
    "# each element of inputs is [batch_size,vocab_size]\n",
    "\n",
    "# targets is a list of length sequence_length\n",
    "# each element of targets is a 1D vector of length batch_size\n",
    "\n",
    "def _linear(args, output_size, bias, bias_start=0.0, scope=None):\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape().as_list() for a in args]\n",
    "  for shape in shapes:\n",
    "    if len(shape) != 2:\n",
    "      raise ValueError(\"Linear is expecting 2D arguments: %s\" % str(shapes))\n",
    "    if not shape[1]:\n",
    "      raise ValueError(\"Linear expects shape[1] of arguments: %s\" % str(shapes))\n",
    "    else:\n",
    "      total_arg_size += shape[1]\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  with vs.variable_scope(scope or \"Linear\"):\n",
    "    matrix = vs.get_variable(\n",
    "        \"Matrix\", [total_arg_size, output_size], dtype=dtype)\n",
    "    if len(args) == 1:\n",
    "      res = math_ops.matmul(args[0], matrix)\n",
    "    else:\n",
    "      res = math_ops.matmul(array_ops.concat(1, args), matrix)\n",
    "    if not bias:\n",
    "      return res\n",
    "    bias_term = vs.get_variable(\n",
    "        \"Bias\", [output_size],\n",
    "        dtype=dtype,\n",
    "        initializer=init_ops.constant_initializer(\n",
    "            bias_start, dtype=dtype))\n",
    "  return res + bias_term\n",
    "\n",
    "class GRUCell(rnn_cell.RNNCell):\n",
    "    def __init__(self, num_units, input_size=None, activation=tanh):\n",
    "        self._num_units = num_units\n",
    "        self._activation = activation\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        with vs.variable_scope(scope or type(self).__name__):\n",
    "            with vs.variable_scope(\"Gates\"):\n",
    "                r, u = array_ops.split(1, 2, _linear([inputs, state], 2 * self._num_units, True, 1.0))\n",
    "                r, u = sigmoid(r), sigmoid(u)\n",
    "            with vs.variable_scope(\"Candidate\"):\n",
    "                c = self._activation(_linear([inputs, r * state], self._num_units, True))\n",
    "            new_h = u * state + (1 - u) * c\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# YOUR COMPUTATION GRAPH HERE\n",
    "with tf.variable_scope(\"COMPUTATION\", reuse=None):\n",
    "    # create a BasicLSTMCell\n",
    "    cell = GRUCell(state_dim)  # True )\n",
    "\n",
    "    #   use it to create a MultiRNNCell\n",
    "    cell = rnn_cell.MultiRNNCell([cell] * num_layers)\n",
    "\n",
    "    #   use it to create an initial_state\n",
    "    #     note that initial_state will be a *list* of tensors!\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [state_dim, vocab_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "\n",
    "    # call seq2seq.rnn_decoder\n",
    "    outputs, last_state = seq2seq.rnn_decoder(inputs, initial_state, cell)\n",
    "    output = tf.reshape(tf.concat(1, outputs), [-1, state_dim])\n",
    "\n",
    "    # transform the list of state outputs to a list of logits.\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    # use a linear transformation.\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    # call seq2seq.sequence_loss\n",
    "    loss = seq2seq.sequence_loss([logits],\n",
    "                                 [tf.reshape(targets, [-1])],\n",
    "                                 [tf.ones([batch_size * sequence_length])],\n",
    "                                 vocab_size)\n",
    "    cost = tf.reduce_sum(loss) / batch_size / sequence_length\n",
    "    final_state = last_state\n",
    "    lr = tf.Variable(0.0, trainable=False)\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "\n",
    "    # create a training op using the Adam optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "# ------------------\n",
    "# YOUR SAMPLER GRAPH HERE\n",
    "\n",
    "# place your sampler graph here it will look a lot like your\n",
    "# computation graph, except with a \"batch_size\" of 1.\n",
    "\n",
    "with tf.variable_scope(\"COMPUTATION\", reuse=True):\n",
    "    s_in_ph = tf.placeholder(tf.int32, [1], name='s_in_ph')\n",
    "    s_inputs = [tf.one_hot(s_in_ph, vocab_size, name=\"s_inputs\")]\n",
    "\n",
    "    #   use it to create a MultiRNNCell\n",
    "    # scope.reuse_variables()\n",
    "    s_cell = GRUCell(state_dim)  # True )\n",
    "\n",
    "    #   use it to create a MultiRNNCell\n",
    "    s_cell = rnn_cell.MultiRNNCell([s_cell] * num_layers)\n",
    "\n",
    "    s_initial_state = s_cell.zero_state(1, tf.float32)\n",
    "\n",
    "    s_outputs, s_final_state = seq2seq.rnn_decoder(s_inputs, s_initial_state, s_cell)\n",
    "    # s_final_state = tf.reshape(tf.concat(1, s_outputs), [-1, state_dim])\n",
    "\n",
    "    # print (\"Shape\", s_outputs.get_shape())\n",
    "    # print (\"softmax_w \", softmax_w.get_shape())\n",
    "    logits = tf.matmul(s_outputs[0], softmax_w) + softmax_b\n",
    "    s_probs = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "#\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "#\n",
    "\n",
    "def sample(num=200, prime='ab'):\n",
    "    # prime the pump\n",
    "\n",
    "    # generate an initial state. this will be a list of states, one for\n",
    "    # each layer in the multicell.\n",
    "    s_state = sess.run(s_initial_state)\n",
    "\n",
    "    # for each character, feed it into the sampler graph and\n",
    "    # update the state.\n",
    "    for char in prime[:-1]:\n",
    "        x = np.ravel(data_loader.vocab[char]).astype('int32')\n",
    "        feed = {s_in_ph: x}\n",
    "        for i, s in enumerate(s_initial_state):\n",
    "            feed[s] = s_state[i]\n",
    "        s_state = sess.run(s_final_state, feed_dict=feed)\n",
    "\n",
    "    # now we have a primed state vector; we need to start sampling.\n",
    "    ret = prime\n",
    "    char = prime[-1]\n",
    "    for n in range(num):\n",
    "        x = np.ravel(data_loader.vocab[char]).astype('int32')\n",
    "\n",
    "        # plug the most recent character in...\n",
    "        feed = {s_in_ph: x}\n",
    "        for i, s in enumerate(s_initial_state):\n",
    "            feed[s] = s_state[i]\n",
    "        ops = [s_probs]\n",
    "        ops.extend(list(s_final_state))\n",
    "\n",
    "        retval = sess.run(ops, feed_dict=feed)\n",
    "\n",
    "        s_probs_ = retval[0]\n",
    "        s_state = retval[1:]\n",
    "\n",
    "        # ...and get a vector of probabilities out!\n",
    "\n",
    "        # now sample (or pick the argmax)\n",
    "        # sample = np.argmax( s_probsv[0] )\n",
    "        sample = np.random.choice(vocab_size, p=s_probs_[0])\n",
    "\n",
    "        pred = data_loader.chars[sample]\n",
    "        ret += pred\n",
    "        char = pred\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND 186 BATCHES\n",
      "0 0\t4.1643\n",
      "And llgkExc\n",
      "EDNvrZdF7'Ewk'n!jcuFKJL'KEnhlkEvN9eltZw!1 6gkwnz1W:V\n",
      "1 0\t4.1643\n",
      "And oNLKoLxNn94\n",
      "Ul\n",
      "elrmmLnDI';In  lw1KknkDilplNh9L'9!.O Fvo'rgwr\n",
      "2 0\t4.1643\n",
      "And nO n\n",
      "o7'GaFdnlvekJlp'g\n",
      "'l1lHvKwkv1Z91nHv1FIpeZ9bq!bR9v:kj7Jo\n",
      "3 0\t4.1643\n",
      "And  zDg-lLNlIn2e'.vDB9d9L9k(!DldF99ffZN(O)ln7V3WZl\n",
      "  'l5SNLEdwl\n",
      "4 0\t4.1643\n",
      "And lebLlfov O\n",
      "hvKk3o1ck1xFcZ1esK''ZkkJEW' mrnlHp9ye111EkyKvNKh \n",
      "5 0\t4.1643\n",
      "And lglCFfJdwlN''ckh7h!\n",
      "DLbDvNIDEGrZNkdkOUZka\n",
      "co9.kN1ekolNbv6EF'\n",
      "6 0\t4.1643\n",
      "And vNvax9Nz?EbN:G?1kt!7kL dhJ9BK.FOI'wnZ1tFC\n",
      "OhD7!DV n'.I1YP.l(\n",
      "7 0\t4.1643\n",
      "And '19ro!NrNfKLLgelhv!Jh1EzqRjwv9dZZnw3flsJ'IEkqD.1DYEmEELde\n",
      "hj\n",
      "8 0\t4.1643\n",
      "And e howgvb:nlD5Kvhlnak9GDZN:v'(9Mdl9oLnKlFF1.lsf3Evo6pZWd\n",
      "c .3\n",
      "9 0\t4.1643\n",
      "And g2cZKbjvLlKloYJawk9GklwnkDzz'GKZ'.gNzCl1LLb\n",
      "JqlwE73wkdF'.di.\n",
      "10 0\t4.1643\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "summary_writer = tf.train.SummaryWriter(\"./tf_logs\", graph=sess.graph)\n",
    "\n",
    "lts = []\n",
    "\n",
    "print \"FOUND %d BATCHES\" % data_loader.num_batches\n",
    "\n",
    "for j in range(1000):\n",
    "\n",
    "    state = sess.run(initial_state)\n",
    "    data_loader.reset_batch_pointer()\n",
    "\n",
    "    for i in range(data_loader.num_batches):\n",
    "\n",
    "        x, y = data_loader.next_batch()\n",
    "\n",
    "        # we have to feed in the individual states of the MultiRNN cell\n",
    "        feed = {in_ph: x, targ_ph: y}\n",
    "        for k, s in enumerate(initial_state):\n",
    "            feed[s] = state[k]\n",
    "\n",
    "        ops = [train_op, loss]\n",
    "        ops.extend(list(final_state))\n",
    "\n",
    "        # retval will have at least 3 entries:\n",
    "        # 0 is None (triggered by the optim op)\n",
    "        # 1 is the loss\n",
    "        # 2+ are the new final states of the MultiRNN cell\n",
    "        retval = sess.run(ops, feed_dict=feed)\n",
    "\n",
    "        lt = retval[1]\n",
    "        state = retval[2:]\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print \"%d %d\\t%.4f\" % (j, i, lt)\n",
    "            lts.append(lt)\n",
    "\n",
    "    print sample(num=60, prime=\"And \")\n",
    "# print sample( num=60, prime=\"ababab\" )\n",
    "#    print sample( num=60, prime=\"foo ba\" )\n",
    "#    print sample( num=60, prime=\"abcdab\" )\n",
    "\n",
    "summary_writer.close()\n",
    "\n",
    "#\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "# ==================================================================\n",
    "#\n",
    "\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot( lts )\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
